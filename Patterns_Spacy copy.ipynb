{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/allennlp/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "def dep_pattern(doc):\n",
    "  for i in range(len(doc)-1):\n",
    "    if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and  doc[i+2].dep_ == 'ROOT':\n",
    "      for tok in doc[i+2].children:\n",
    "        if tok.dep_ == 'dobj':\n",
    "          return True\n",
    "  return False\n",
    "doc = nlp(u'We can overtake them.')\n",
    "if dep_pattern(doc):\n",
    "  print('Found')\n",
    "else:\n",
    "  print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span:  We can overtake\n",
      "The positions in the doc are:  0 - 3\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"aux\"}, {\"DEP\": \"ROOT\"}]\n",
    "matcher.add(\"NsubjAuxRoot\", [pattern])\n",
    "doc = nlp(u\"We can overtake them.\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "  span = doc[start:end]\n",
    "  print(\"Span: \", span.text)\n",
    "  print(\"The positions in the doc are: \", start, \"-\", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "# multi-pattern i.e., patterns based on both POS + DEP\n",
    "def dep_pattern(doc):\n",
    "  for i in range(len(doc)-1):\n",
    "    if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and  doc[i+2].dep_ == 'ROOT':\n",
    "      for tok in doc[i+2].children:\n",
    "        if tok.dep_ == 'dobj':\n",
    "          return True\n",
    "  return False\n",
    "def pos_pattern(doc):\n",
    "  for token in doc:\n",
    "    if token.dep_ == 'nsubj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "    if token.dep_ == 'aux' and token.tag_ != 'MD':\n",
    "      return False\n",
    "    if token.dep_ == 'ROOT' and token.tag_ != 'VB':\n",
    "      return False\n",
    "    if token.dep_ == 'dobj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "  return True\n",
    "#Testing code\n",
    "doc = nlp(u'We can overtake them.')\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "  print('Found')\n",
    "else:\n",
    "  print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product sales hit 18.6 million units sold\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"The product sales hit a new record in the first quarter, with 18.6 million units sold.\")\n",
    "phrase = ''\n",
    "for token in doc:\n",
    "  if token.pos_ == 'NUM':\n",
    "    while True:\n",
    "      phrase = phrase + ' ' + token.text\n",
    "      token = token.head\n",
    "      if token not in list(token.head.lefts):\n",
    "        phrase = phrase + ' ' + token.text\n",
    "        if list(token.rights):\n",
    "          phrase = phrase + ' ' + doc[token.i+1:].text\n",
    "        break\n",
    "    break\n",
    "while True:\n",
    "  token = doc[token.i].head\n",
    "  if token.pos_ != 'ADP':\n",
    "    phrase = token.text + phrase\n",
    "  if token.dep_ == 'ROOT':\n",
    "    break\n",
    "for tok in token.lefts:\n",
    "  if tok.dep_ == 'nsubj':\n",
    "    phrase = ' '.join([tok.text for tok in tok.lefts]) + ' ' + tok.text + ' '+ phrase\n",
    "    break\n",
    "print(phrase.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishnaming 20 from 20, moving from any starting point\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Establish understanding of the language and processes of counting by naming numbers in sequences, initially to and from 20, moving from any starting point\")\n",
    "phrase = ''\n",
    "for token in doc:\n",
    "  if token.pos_ == 'NUM':\n",
    "    while True:\n",
    "      phrase = phrase + ' ' + token.text\n",
    "      token = token.head\n",
    "      if token not in list(token.head.lefts):\n",
    "        phrase = phrase + ' ' + token.text\n",
    "        if list(token.rights):\n",
    "          phrase = phrase + ' ' + doc[token.i+1:].text\n",
    "        break\n",
    "    break\n",
    "while True:\n",
    "  token = doc[token.i].head\n",
    "  if token.pos_ != 'ADP':\n",
    "    phrase = token.text + phrase\n",
    "  if token.dep_ == 'ROOT':\n",
    "    break\n",
    "for tok in token.lefts:\n",
    "  if tok.dep_ == 'nsubj':\n",
    "    phrase = ' '.join([tok.text for tok in tok.lefts]) + ' ' + tok.text + ' '+ phrase\n",
    "    break\n",
    "print(phrase.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the action verb extracted:  Establish\n",
      "Establish\n",
      "the action verb extracted:  Establish\n",
      "direction object is :  understanding\n",
      "understanding of\n",
      "understanding of\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'understanding of'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-pattern i.e., patterns based on both POS + DEP\n",
    "def dep_pattern(doc):\n",
    "  for i in range(len(doc)-1):\n",
    "    if doc[i].tag_ == 'VERB' and doc[i+1].dep_ == 'dobj':\n",
    "      for tok in doc[i+2].children:\n",
    "        if tok.dep_ == 'dobj':\n",
    "          return True\n",
    "  return False\n",
    "\n",
    "def extract_action_verb(doc):\n",
    "  if doc[0].tag_ == 'VB' and doc[0].dep_ == 'ROOT':\n",
    "    actionVerb = doc[0]\n",
    "    print (\"the action verb extracted: \", actionVerb.text)\n",
    "    \n",
    "    return actionVerb\n",
    "\n",
    "\n",
    "def extract_content(doc):\n",
    "  actionVerb = extract_action_verb(doc)\n",
    "\n",
    "  phrase = ''\n",
    "\n",
    "  for i in actionVerb.rights:\n",
    "    if i.dep_ == 'dobj':\n",
    "      print(\"direction object is : \", i.text)\n",
    "      \n",
    "      phrase = i.text;\n",
    "      while True:\n",
    "      x i.rights:\n",
    "        phrase = phrase + ' ' + x.text\n",
    "        if x.dep_ == 'pobj':\n",
    "          continue\n",
    "    print (phrase)\n",
    "  return phrase\n",
    "\n",
    "\n",
    "\n",
    "def pos_pattern(doc):\n",
    "  for token in doc:\n",
    "    if token.dep_ == 'nsubj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "    if token.dep_ == 'aux' and token.tag_ != 'MD':\n",
    "      return False\n",
    "    if token.dep_ == 'ROOT' and token.tag_ != 'VB':\n",
    "      return False\n",
    "    if token.dep_ == 'dobj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "  return True\n",
    "#Testing code\n",
    "doc = nlp('Establish understanding of the language and processes of counting by naming numbers in sequences, initially to and from 20, moving from any starting point')\n",
    "\n",
    "actionVerb= extract_action_verb(doc)\n",
    "print(actionVerb.text)\n",
    "\n",
    "extract_content(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the different contribution\n",
      "words\n",
      "images\n",
      "meaning\n",
      "stories\n",
      "informative texts\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"the different contribution of words and images to meaning in stories and informative texts\")\n",
    "\n",
    "for chunks in doc.noun_chunks:\n",
    "    print(chunks.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action verb:  Explore\n",
      "context:  how language is used differently at home and school depending on the relationships between people\n",
      "span1:  depending on the relationships between people\n",
      "span1 features (subtree):  ['depending', 'on', 'the', 'relationships', 'between', 'people']\n",
      "span1 features (root):  depending\n",
      "span1 features (tensor):  []\n",
      "span1 label:  \n",
      "sentence:  Explore how language is used differently at home and school depending on the relationships between people\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Explore how language is used differently at home and school depending on the relationships between people\")\n",
    "\n",
    "spanActionVerb = doc[0:1]\n",
    "spanCotext = doc[1:len(doc)]\n",
    "span1 = doc[10:16]\n",
    "\n",
    "print(\"action verb: \" , spanActionVerb.text)\n",
    "print(\"context: \",spanCotext.text)\n",
    "\n",
    "print(\"span1: \", span1.text) \n",
    "print(\"span1 features (subtree): \", [t.text for t  in span1.subtree])\n",
    "print(\"span1 features (root): \", span1.root)\n",
    "print(\"span1 features (tensor): \", span1.tensor)\n",
    "print(\"span1 label: \", span1.label_)\n",
    "\n",
    "\n",
    "print(\"sentence: \", spanActionVerb.sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "home\n",
      "school\n",
      "the relationships\n",
      "people\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Explore how language is used differently at home and school depending on the relationships between people\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b15a425c007d4276677af8065ed86cef8b67a017320d3967defa30d7a3a9336"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
